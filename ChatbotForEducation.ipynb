{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1PbOtu9m0XnvLlp-VGxTYb88-GeN_VlqE",
      "authorship_tag": "ABX9TyMFyROqwl1VGF6YJRR+7rGk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pierobaffa/ChatbotForEducation/blob/main/ChatbotForEducation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VwCMeiIV8Nk"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.utils import shuffle\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense  \n",
        "from random import choice"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/intents.json\") as model_file:\n",
        "    data = json.load(model_file)"
      ],
      "metadata": {
        "id": "B6Iyxokj-0qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "N0Hx5s_HeWKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = set({})\n",
        "intents = []\n",
        "patterns = []"
      ],
      "metadata": {
        "id": "3r0INVweeZF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for intent in data[\"intents\"]:\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "        pattern = pattern.lower()\n",
        "        tokens = nlp(pattern)\n",
        "        doc = \"\"\n",
        "        for token in tokens:\n",
        "            if(not token.is_punct and not token.is_stop):\n",
        "                doc+=\" \"+token.lemma_\n",
        "                dictionary.add(token.lemma_)\n",
        "        if(len(doc)>0):\n",
        "            patterns.append(doc.strip())\n",
        "            intents.append(intent[\"tag\"])"
      ],
      "metadata": {
        "id": "PmCxDCqBebX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow = CountVectorizer() \n",
        "X = bow.fit_transform(patterns) \n",
        "X = X.toarray()\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(intents)\n",
        "\n",
        "ohe = OneHotEncoder()\n",
        "y = ohe.fit_transform(y.reshape(-1, 1)) \n",
        "y = y.toarray()\n",
        "\n",
        "X, y = shuffle(X, y, random_state=0)"
      ],
      "metadata": {
        "id": "4FcrBdglef5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(12, activation=\"relu\", input_dim=X.shape[1]))\n",
        "model.add(Dense(8, activation=\"relu\"))\n",
        "model.add(Dense(y.shape[1], activation=\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "GJmCRybzeicC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=500)"
      ],
      "metadata": {
        "id": "VLbeUPzMelGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(sentence):\n",
        "    tokens = nlp(sentence.lower())\n",
        "    doc = \"\"\n",
        "    for token in tokens:\n",
        "        if(not token.is_punct and not token.is_stop):\n",
        "            doc+=\" \"+token.lemma_ \n",
        "    x = bow.transform([doc])\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "def get_response(intent_name):\n",
        "    for intent in data[\"intents\"]:\n",
        "      if(intent[\"tag\"]==intent_name):\n",
        "        return choice(intent[\"responses\"])\n",
        "    \n",
        "def chatbot(sentence):\n",
        "    x = preprocess(sentence)\n",
        "    y_proba = model.predict(x)[0]\n",
        "    if(y_proba.max()>.7):\n",
        "        y = y_proba.argmax()\n",
        "        intent = le.inverse_transform([y])\n",
        "        return get_response(intent)\n",
        "    else:\n",
        "      return \"Sorry, I don't understand\"\n",
        "  \n",
        "\n",
        "sentence = \"\"\n",
        "while(sentence.lower()!=\"goodbye\"):\n",
        "  sentence = input(\"You: \")\n",
        "  response = chatbot(sentence)\n",
        "  print(\"Chatbot: \"+response) "
      ],
      "metadata": {
        "id": "xhxl1xCvesDZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}